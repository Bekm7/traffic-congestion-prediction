{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5df37-90e6-4a68-b885-135ed1281d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Load your FINAL dataset  \n",
    "df = pd.read_csv(\"D:/traffic-congestion-predictor/data/processed/final_modeling_data.csv\", parse_dates=['pickup_hour_dt'])  \n",
    "\n",
    "# Verify columns (should match your selected features)    \n",
    "#df.describe()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6c14d-e64f-40a6-843d-8305cbcd29d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop speed outliers\n",
    "df = df[df['avg_speed'] <= 60].copy()\n",
    "\n",
    "# Drop rows with missing borough/zone \n",
    "df.dropna(subset=['PUBorough', 'DOBorough', 'PUZone', 'DOZone'], inplace=True)\n",
    "\n",
    "#Frequency encoding high-cardinality categorical features\n",
    "for col in ['PUBorough', 'DOBorough', 'PUZone', 'DOZone']:\n",
    "    freq_map = df[col].value_counts(normalize=True)\n",
    "    df[f'{col}_freq'] = df[col].map(freq_map)\n",
    "\n",
    "#encoding pickup days as they are in object dtypes(low cardinality)\n",
    "df = pd.get_dummies(df, columns=['pickup_day'])#, drop_first=True)\n",
    "\n",
    "\n",
    "#Reset index after cleaning\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ec60d-9b24-4b49-bc86-7876ebd1a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "#df.to_csv(\"D:/traffic-congestion-predictor/data/processed/xbdata_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac0636-47ca-4dd6-b4ea-213b9199e326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee311f54-8190-4728-a0b8-683c0647f08e",
   "metadata": {},
   "source": [
    "##FEATURE SELECTION AND CORRELATION HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9087f7f-9f38-4c0d-85d1-9028cccd878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Sort correlations with target\n",
    "target_corr = corr_matrix['avg_speed'].sort_values(ascending=False)\n",
    "\n",
    "# Print top 10 positively and negatively correlated features\n",
    "print(\"Top positive correlations:\\n\", target_corr.head(10))\n",
    "print(\"\\nTop negative correlations:\\n\", target_corr.tail(10))\n",
    "\n",
    "# Plot full heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig(\"D:/traffic-congestion-predictor/outputs/plots/correlation_heatmap.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78304592-0a11-4197-b197-5a13f43d39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features to keep\n",
    "#selected_features = [\n",
    "   # 'pickup_hour',\n",
    "    #'pickup_day_Monday', 'pickup_day_Sunday',  # Only high-corr ones\n",
    "    #'is_rush_hour',\n",
    "    #'is_midweek',\n",
    "\n",
    "    #'PULocationID', 'DOLocationID',\n",
    "    #'PUZone_freq', 'DOZone_freq',\n",
    "    #'PUBorough_freq', 'DOBorough_freq',\n",
    "\n",
    "    #'temp', 'prcp', 'wspd', 'snowed', 'coco'\n",
    "\n",
    "#target = 'avg_speed'\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f7953-181d-4798-beb3-bc1c761b9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --user xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159243d-37d2-414e-a6d1-9f729273f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scikit-learn\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29346417-0f51-46b5-be92-e27fda0fc7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Features & Target\n",
    "# ----------------------------\n",
    "features = [\n",
    "    'pickup_hour', 'pickup_day_Sunday', 'pickup_day_Monday',\n",
    "    'is_rush_hour', 'is_midweek',\n",
    "    'PULocationID', 'DOLocationID',\n",
    "    'PUZone_freq', 'DOZone_freq',\n",
    "    'PUBorough_freq', 'DOBorough_freq',\n",
    "    'temp', 'prcp', 'wspd', 'snowed', 'coco'\n",
    "]\n",
    "target = 'avg_speed'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# ----------------------------\n",
    "# Train-Test Split\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Standardization (optional but helps)\n",
    "# ----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------\n",
    "# Linear Regression\n",
    "# ----------------------------\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# Prediction & Evaluation\n",
    "# ----------------------------\n",
    "y_pred = lr.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "#rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "#r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Linear Regression RMSE: {rmse:.3f}\")\n",
    "print(f\"Linear Regression R²: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced4ae2d-0c60-4c20-aba9-d66dea4c27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174c341-4769-4227-a691-1eb470d9f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=300, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_rmse=np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest RMSE: {rf_rmse:.3f}\")\n",
    "print(f\"Random Forest R²: {rf_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66b212-234f-476d-91bc-7df419208d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cdadde-c549-47e6-b70a-470f32b538b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "xgb_mse = mean_squared_error(y_test, y_pred_xgb)\n",
    "xgb_rmse=np.sqrt(xgb_mse)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost RMSE: {xgb_rmse:.3f}\")\n",
    "print(f\"XGBoost R²: {xgb_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca5ce7-4284-404f-a940-0cd71fe855d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = xgb.feature_importances_\n",
    "feature_names = X.columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"XGBoost Feature Importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "plt.xticks(range(X.shape[1]), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"D:/traffic-congestion-predictor/outputs/plots/xgb1_feature_importance.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030ffb53-8919-4e22-bf80-67b553e745db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Set up parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [3, 4, 5, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # keep it light\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse=np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"Tuned XGBoost RMSE: {rmse:.3f}\")\n",
    "print(f\"Tuned XGBoost R²: {r2:.3f}\")\n",
    "print(\"Best Params:\", random_search_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075947bc-3a97-4b81-bafa-682aac69b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Param grid for RF\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "best_rf = rf_random_search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_rmse=np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Tuned Random Forest RMSE: {rf_rmse:.3f}\")\n",
    "print(f\"Tuned Random Forest R²: {rf_r2:.3f}\")\n",
    "print(\"Best Params:\", rf_random_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ab7dc-e901-4f84-aaa1-1b9a15169799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
